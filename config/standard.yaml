defaults: &defaults
  install_variant: "{arch}"

  max_duration: 600

  voir:
    options:
      stop: 60
      interval: "1s"


torchvision: &torchvision
  <<<: *defaults

  group: torchvision
  install_group: torch

  plan:
    method: per_gpu

  argv:
    --with-amp: true
    --lr: 0.01

  definition: ../benchmarks/torchvision


hf: &hf
  <<<: *defaults

  group: hf
  install_group: torch

  plan:
    method: per_gpu

  definition: ../benchmarks/huggingface


lightning: &lightning
  <<<: *defaults

  group: lightning
  install_group: torch

  plan:
    method: njobs
    n: 1

  definition: ../benchmarks/pytorch-lightning

  argv:
    --max_epochs: 1
    --max_steps: 100
    --limit_val_batches: 100
    --devices: -1
    --enable_progress_bar: "False"
    --accelerator: "auto"
    --enable_checkpointing: "False"

##############
# Benchmarks #
##############

benchmarks:
  resnet50-fp16:
    <<<: *torchvision
    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: resnet50
      --batch-size: $(bs(gpu, mem, default=512))
      --with-amp: True

    mem:
      slope: 82
      intercept: 2728
      multiple: 16

  resnet50-fp32:
    <<<: *torchvision
    tags:
      - vision
      - classification
      - cnn
      - fp32
      - e2e

    argv:
      --model: resnet50
      --batch-size: $(bs(gpu, mem, default=256))
      --with-amp: null

    mem:
      slope: 90
      intercept: 2985
      multiple: 16

<<<<<<< HEAD
  squeezenet1_1:
    <<<: *torchvision
    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: squeezenet1_1
      --batch-size: $(bs(gpu, mem, default=256))

    mem:
      slope: 19
      intercept: 3166
      multiple: 16

  efficientnet_b0:
    <<<: *torchvision
    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: efficientnet_b0
      --batch-size: $(bs(gpu, mem, default=256))

    mem:
      slope: 47
      intercept: 2570
      multiple: 16

=======
>>>>>>> 04af453c683076d67ea603394c38d25d2b3f2ee0
  efficientnet_b4:
    <<<: *torchvision
    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e 
   
    argv:
      --model: efficientnet_b4
      --batch-size: $(bs(gpu, mem, default=256))

    mem:
      slope: 115
      intercept: 2765
      multiple: 16

  efficientnet_b7:
    <<<: *torchvision
    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: efficientnet_b7
      --batch-size: $(bs(gpu, mem, default=64))

    mem:
      slope: 264
      intercept: 3236
      multiple: 16

  convnext_large:
    <<<: *torchvision
    tags:
      - vision
      - classification
      - cnn
      - fp16
      - e2e

    argv:
      --model: convnext_large
      --batch-size: $(bs(gpu, mem, default=256))

    mem:
      slope: 190
      intercept: 4090
      multiple: 16

  regnet_y_128gf:
    <<<: *torchvision
    tags:
      - vision
      - classification
      - cnn
      - fp32
      - lstm
      - e2e

    argv:
      --model: regnet_y_128gf
      --batch-size: $(bs(gpu, mem, default=32))
      --with-amp: null

    mem:
      slope: 826
      intercept: 5290
      multiple: 16

  bert:
    <<<: *hf
    tags:
      - nlp
      - language-modeling
      - transformer
      - no-io
      - huggingface
    argv:
      --model: "Bert"
      --batch-size: $(bs(gpu, mem, default=16))
    mem:
      slope: 1000
      intercept: 3774
      multiple: 8

  t5:
    <<<: *hf
    tags:
      - huggingface
      - nlp
      - language_modeling
      - transformer
      - huggingface
      - no-io
    argv:
      --model: "T5"
      --batch-size: $(bs(gpu, mem, default=16))
    mem:
      slope: 2683
      intercept: 1916
      multiple: 8

  reformer:
    <<<: *hf
    tags:
      - huggingface
      - nlp
      - language-modeling
      - transformer
      - huggingface
      - no-io
    argv:
      --model: "Reformer"
      --batch-size: $(bs(gpu, mem, default=16))
    mem:
      slope: 385
      intercept: 1464
      multiple: 8

  resnet152:
    <<<: *lightning
    tags:
      - vision
      - classification
      - cnn
    argv:
      --backbone: "resnet152"
      --strategy: "ddp"
      --precision: 32
      --batch_size: 2048
      --max_epochs: 100
      --max_steps: 1000
      --batch_size: $(bs(gpu, mem, default=12, multi_gpu=True))
    mem:
      slope: 4.23
      intercept: 3323
      multiple: 16

<<<<<<< HEAD
  vit_l_32:
    <<<: *lightning
    tags:
      - vision
      - classification
      - transformer
    argv:
      --backbone: "vit_l_32"  # (larger model)
      --strategy: "fsdp"  # Fully-Sharded Data-Parallel
      --precision: 32
=======
  accelerate:
    <<<: *defaults
>>>>>>> 04af453c683076d67ea603394c38d25d2b3f2ee0

    install_group: torch

    plan:
      method: njobs
      n: 1

    # This is for single-node
    manager_addr: "127.0.0.1"
    manager_port: 10000

    num_processes: 2
    cpus_per_gpu: 8

    # model_name: "facebook/opt-350m"
    model_name: "facebook/opt-2.7b"
    #model_name: "facebook/opt-1.3b"
    #model_name: "facebook/opt-125m"

    gradient_accumulation_steps: 1
    per_gpu_batch_size: 1
    max_train_steps: 30

    dataset_name: "wikitext"
    dataset_config_name: "wikitext-103-v1"
    validation_split_percentage: 5

    definition: ../benchmarks/accelerate_opt

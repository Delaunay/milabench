#!/bin/sh

# ---
# llama
# =====
(
  CUDA_VISIBLE_DEVICES=0 python $MILABENCH_SRC/benchmarks/llama/main.py --cache $MILABENCH_BASE/cache &
  CUDA_VISIBLE_DEVICES=1 python $MILABENCH_SRC/benchmarks/llama/main.py --cache $MILABENCH_BASE/cache &
  CUDA_VISIBLE_DEVICES=2 python $MILABENCH_SRC/benchmarks/llama/main.py --cache $MILABENCH_BASE/cache &
  CUDA_VISIBLE_DEVICES=3 python $MILABENCH_SRC/benchmarks/llama/main.py --cache $MILABENCH_BASE/cache &
  CUDA_VISIBLE_DEVICES=4 python $MILABENCH_SRC/benchmarks/llama/main.py --cache $MILABENCH_BASE/cache &
  CUDA_VISIBLE_DEVICES=5 python $MILABENCH_SRC/benchmarks/llama/main.py --cache $MILABENCH_BASE/cache &
  CUDA_VISIBLE_DEVICES=6 python $MILABENCH_SRC/benchmarks/llama/main.py --cache $MILABENCH_BASE/cache &
  CUDA_VISIBLE_DEVICES=7 python $MILABENCH_SRC/benchmarks/llama/main.py --cache $MILABENCH_BASE/cache &
  wait
)

# ---
# fp16
# ====
(
  CUDA_VISIBLE_DEVICES=0 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 30 --repeat 90 --m 8192 --n 8192 --dtype fp16 &
  CUDA_VISIBLE_DEVICES=1 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 30 --repeat 90 --m 8192 --n 8192 --dtype fp16 &
  CUDA_VISIBLE_DEVICES=2 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 30 --repeat 90 --m 8192 --n 8192 --dtype fp16 &
  CUDA_VISIBLE_DEVICES=3 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 30 --repeat 90 --m 8192 --n 8192 --dtype fp16 &
  CUDA_VISIBLE_DEVICES=4 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 30 --repeat 90 --m 8192 --n 8192 --dtype fp16 &
  CUDA_VISIBLE_DEVICES=5 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 30 --repeat 90 --m 8192 --n 8192 --dtype fp16 &
  CUDA_VISIBLE_DEVICES=6 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 30 --repeat 90 --m 8192 --n 8192 --dtype fp16 &
  CUDA_VISIBLE_DEVICES=7 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 30 --repeat 90 --m 8192 --n 8192 --dtype fp16 &
  wait
)

# ---
# bf16
# ====
(
  CUDA_VISIBLE_DEVICES=0 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype bf16 &
  CUDA_VISIBLE_DEVICES=1 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype bf16 &
  CUDA_VISIBLE_DEVICES=2 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype bf16 &
  CUDA_VISIBLE_DEVICES=3 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype bf16 &
  CUDA_VISIBLE_DEVICES=4 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype bf16 &
  CUDA_VISIBLE_DEVICES=5 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype bf16 &
  CUDA_VISIBLE_DEVICES=6 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype bf16 &
  CUDA_VISIBLE_DEVICES=7 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype bf16 &
  wait
)

# ---
# tf32
# ====
(
  CUDA_VISIBLE_DEVICES=0 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 --tf32 &
  CUDA_VISIBLE_DEVICES=1 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 --tf32 &
  CUDA_VISIBLE_DEVICES=2 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 --tf32 &
  CUDA_VISIBLE_DEVICES=3 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 --tf32 &
  CUDA_VISIBLE_DEVICES=4 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 --tf32 &
  CUDA_VISIBLE_DEVICES=5 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 --tf32 &
  CUDA_VISIBLE_DEVICES=6 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 --tf32 &
  CUDA_VISIBLE_DEVICES=7 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 --tf32 &
  wait
)

# ---
# fp32
# ====
(
  CUDA_VISIBLE_DEVICES=0 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 &
  CUDA_VISIBLE_DEVICES=1 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 &
  CUDA_VISIBLE_DEVICES=2 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 &
  CUDA_VISIBLE_DEVICES=3 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 &
  CUDA_VISIBLE_DEVICES=4 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 &
  CUDA_VISIBLE_DEVICES=5 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 &
  CUDA_VISIBLE_DEVICES=6 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 &
  CUDA_VISIBLE_DEVICES=7 $MILABENCH_SRC/benchmarks/flops/activator $MILABENCH_BASE/venv/torch $MILABENCH_SRC/benchmarks/flops/main.py --number 10 --repeat 90 --m 8192 --n 8192 --dtype fp32 &
  wait
)

# ---
# resnet50
# ========
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-resnet50.D0-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model resnet50 --batch-size 64 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-resnet50.D1-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model resnet50 --batch-size 64 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-resnet50.D2-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model resnet50 --batch-size 64 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-resnet50.D3-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model resnet50 --batch-size 64 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-resnet50.D4-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model resnet50 --batch-size 64 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-resnet50.D5-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model resnet50 --batch-size 64 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-resnet50.D6-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model resnet50 --batch-size 64 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-resnet50.D7-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model resnet50 --batch-size 64 &
  wait
)

# ---
# convnext_large-fp32
# ===================
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp32.D0-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp32.D1-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp32.D2-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp32.D3-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp32.D4-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp32.D5-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp32.D6-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp32.D7-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  wait
)

# ---
# convnext_large-fp16
# ===================
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp16.D0-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp16.D1-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp16.D2-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp16.D3-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp16.D4-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp16.D5-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp16.D6-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-fp16.D7-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  wait
)

# ---
# convnext_large-tf32
# ===================
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32.D0-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32.D1-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32.D2-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32.D3-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32.D4-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32.D5-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32.D6-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32.D7-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  wait
)

# ---
# convnext_large-tf32-fp16
# ========================
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32-fp16.D0-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32-fp16.D1-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32-fp16.D2-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32-fp16.D3-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32-fp16.D4-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32-fp16.D5-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32-fp16.D6-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-convnext_large-tf32-fp16.D7-fb5679c624c0e6290d39628373b49ebc.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model convnext_large --batch-size 128 &
  wait
)

# ---
# regnet_y_128gf
# ==============
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-regnet_y_128gf.D0-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model regnet_y_128gf --batch-size 64 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-regnet_y_128gf.D1-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model regnet_y_128gf --batch-size 64 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-regnet_y_128gf.D2-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model regnet_y_128gf --batch-size 64 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-regnet_y_128gf.D3-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model regnet_y_128gf --batch-size 64 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-regnet_y_128gf.D4-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model regnet_y_128gf --batch-size 64 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-regnet_y_128gf.D5-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model regnet_y_128gf --batch-size 64 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-regnet_y_128gf.D6-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model regnet_y_128gf --batch-size 64 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/torchvision/voirconf-regnet_y_128gf.D7-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/torchvision/main.py --precision tf32-fp16 --lr 0.01 --no-stdout --epochs 50 --model regnet_y_128gf --batch-size 64 &
  wait
)

# ---
# bert-fp32
# =========
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp32.D0-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp32.D1-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp32.D2-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp32.D3-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp32.D4-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp32.D5-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp32.D6-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp32.D7-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp32 --num-workers 8 --model Bert --batch-size 32 &
  wait
)

# ---
# bert-fp16
# =========
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp16.D0-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp16.D1-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp16.D2-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp16.D3-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp16.D4-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp16.D5-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp16.D6-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-fp16.D7-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision fp16 --num-workers 8 --model Bert --batch-size 32 &
  wait
)

# ---
# bert-tf32
# =========
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32.D0-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32.D1-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32.D2-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32.D3-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32.D4-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32.D5-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32.D6-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32.D7-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32 --num-workers 8 --model Bert --batch-size 32 &
  wait
)

# ---
# bert-tf32-fp16
# ==============
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32-fp16.D0-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32-fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32-fp16.D1-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32-fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32-fp16.D2-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32-fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32-fp16.D3-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32-fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32-fp16.D4-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32-fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32-fp16.D5-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32-fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32-fp16.D6-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32-fp16 --num-workers 8 --model Bert --batch-size 32 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/hf/voirconf-bert-tf32-fp16.D7-fb5679c624c0e6290d39628373b49ebc.json -m bench --precision tf32-fp16 --num-workers 8 --model Bert --batch-size 32 &
  wait
)

# ---
# t5
# ==
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/hf/voirconf-t5.D0-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model T5 --batch-size 16 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/hf/voirconf-t5.D1-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model T5 --batch-size 16 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/hf/voirconf-t5.D2-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model T5 --batch-size 16 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/hf/voirconf-t5.D3-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model T5 --batch-size 16 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/hf/voirconf-t5.D4-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model T5 --batch-size 16 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/hf/voirconf-t5.D5-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model T5 --batch-size 16 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/hf/voirconf-t5.D6-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model T5 --batch-size 16 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/hf/voirconf-t5.D7-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model T5 --batch-size 16 &
  wait
)

# ---
# reformer
# ========
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/hf/voirconf-reformer.D0-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Reformer --batch-size 64 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/hf/voirconf-reformer.D1-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Reformer --batch-size 64 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/hf/voirconf-reformer.D2-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Reformer --batch-size 64 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/hf/voirconf-reformer.D3-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Reformer --batch-size 64 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/hf/voirconf-reformer.D4-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Reformer --batch-size 64 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/hf/voirconf-reformer.D5-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Reformer --batch-size 64 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/hf/voirconf-reformer.D6-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Reformer --batch-size 64 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/hf/voirconf-reformer.D7-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Reformer --batch-size 64 &
  wait
)

# ---
# whisper
# =======
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/hf/voirconf-whisper.D0-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Whisper --batch-size 64 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/hf/voirconf-whisper.D1-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Whisper --batch-size 64 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/hf/voirconf-whisper.D2-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Whisper --batch-size 64 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/hf/voirconf-whisper.D3-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Whisper --batch-size 64 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/hf/voirconf-whisper.D4-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Whisper --batch-size 64 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/hf/voirconf-whisper.D5-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Whisper --batch-size 64 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/hf/voirconf-whisper.D6-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Whisper --batch-size 64 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/hf/voirconf-whisper.D7-0efae956f1553a76c1e03985181900f5.json -m bench --precision tf32-fp16 --num-workers 8 --model Whisper --batch-size 64 &
  wait
)

# ---
# resnet152
# =========
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/timm/voirconf-resnet152.D0-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model resnet152 --batch-size 256 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/resnet152.D0 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/timm/voirconf-resnet152.D1-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model resnet152 --batch-size 256 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/resnet152.D1 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/timm/voirconf-resnet152.D2-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model resnet152 --batch-size 256 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/resnet152.D2 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/timm/voirconf-resnet152.D3-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model resnet152 --batch-size 256 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/resnet152.D3 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/timm/voirconf-resnet152.D4-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model resnet152 --batch-size 256 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/resnet152.D4 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/timm/voirconf-resnet152.D5-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model resnet152 --batch-size 256 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/resnet152.D5 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/timm/voirconf-resnet152.D6-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model resnet152 --batch-size 256 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/resnet152.D6 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/timm/voirconf-resnet152.D7-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model resnet152 --batch-size 256 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/resnet152.D7 --checkpoint-hist 1 &
  wait
)

# ---
# resnet152-multi
# ===============
(
  torchrun --nproc_per_node=8 --no-python -- voir --config $MILABENCH_BASE/extra/timm/voirconf-resnet152-multi.0-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model resnet152 --batch-size 256 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/resnet152-multi.0 --checkpoint-hist 1 &
  wait
)

# ---
# davit_large
# ===========
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/timm/voirconf-davit_large.D0-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model davit_large --batch-size 128 --lr-base 0.01 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/davit_large.D0 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/timm/voirconf-davit_large.D1-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model davit_large --batch-size 128 --lr-base 0.01 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/davit_large.D1 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/timm/voirconf-davit_large.D2-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model davit_large --batch-size 128 --lr-base 0.01 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/davit_large.D2 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/timm/voirconf-davit_large.D3-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model davit_large --batch-size 128 --lr-base 0.01 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/davit_large.D3 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/timm/voirconf-davit_large.D4-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model davit_large --batch-size 128 --lr-base 0.01 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/davit_large.D4 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/timm/voirconf-davit_large.D5-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model davit_large --batch-size 128 --lr-base 0.01 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/davit_large.D5 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/timm/voirconf-davit_large.D6-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model davit_large --batch-size 128 --lr-base 0.01 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/davit_large.D6 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/timm/voirconf-davit_large.D7-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model davit_large --batch-size 128 --lr-base 0.01 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/davit_large.D7 --checkpoint-hist 1 &
  wait
)

# ---
# davit_large-multi
# =================
(
  torchrun --nproc_per_node=8 --no-python -- voir --config $MILABENCH_BASE/extra/timm/voirconf-davit_large-multi.0-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model davit_large --batch-size 128 --lr-base 0.01 --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/davit_large-multi.0 --checkpoint-hist 1 &
  wait
)

# ---
# focalnet
# ========
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/timm/voirconf-focalnet.D0-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model focalnet_base_lrf --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/focalnet.D0 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/timm/voirconf-focalnet.D1-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model focalnet_base_lrf --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/focalnet.D1 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/timm/voirconf-focalnet.D2-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model focalnet_base_lrf --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/focalnet.D2 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/timm/voirconf-focalnet.D3-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model focalnet_base_lrf --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/focalnet.D3 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/timm/voirconf-focalnet.D4-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model focalnet_base_lrf --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/focalnet.D4 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/timm/voirconf-focalnet.D5-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model focalnet_base_lrf --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/focalnet.D5 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/timm/voirconf-focalnet.D6-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model focalnet_base_lrf --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/focalnet.D6 --checkpoint-hist 1 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/timm/voirconf-focalnet.D7-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/timm/pytorch-image-models/train.py --amp --model focalnet_base_lrf --data-dir $MILABENCH_BASE/data --dataset FakeImageNet --output $MILABENCH_BASE/extra/timm/dev/focalnet.D7 --checkpoint-hist 1 &
  wait
)

# ---
# opt-1_3b
# ========
(
  $MILABENCH_SRC/benchmarks/accelerate_opt/activator $MILABENCH_BASE/venv/torch accelerate launch --mixed_precision=fp16 --dynamo_backend=no --machine_rank=0 --num_machines=1 --multi_gpu --gradient_accumulation_steps=1 --num_cpu_threads_per_process=8 --main_process_ip=127.0.0.1 --main_process_port=22 --num_processes=8 $MILABENCH_SRC/benchmarks/accelerate_opt/main.py --max_train_steps 100 --dataset_name wikitext --dataset_config_name wikitext-103-v1 --dataset_rev b08601e --validation_split_percentage 5 --per_gpu_batch_size 1 --cpus_per_gpu 8 --model_name facebook/opt-1.3b --cache $MILABENCH_BASE/cache &
  wait
)

# ---
# opt-1_3b-multinode
# ==================
(
  $MILABENCH_SRC/benchmarks/accelerate_opt/activator $MILABENCH_BASE/venv/torch accelerate launch --mixed_precision=fp16 --dynamo_backend=no --machine_rank=0 --num_machines=2 --multi_gpu --gradient_accumulation_steps=1 --num_cpu_threads_per_process=8 --main_process_ip=127.0.0.1 --main_process_port=22 --num_processes=16 $MILABENCH_SRC/benchmarks/accelerate_opt/main.py --max_train_steps 100 --dataset_name wikitext --dataset_config_name wikitext-103-v1 --dataset_rev b08601e --validation_split_percentage 5 --per_gpu_batch_size 1 --cpus_per_gpu 8 --model_name facebook/opt-1.3b --cache $MILABENCH_BASE/cache &
  ssh -oCheckHostIP=no -oStrictHostKeyChecking=no -oPasswordAuthentication=no -oPasswordAuthentication=no -p 22 username@192.168.0.11 $MILABENCH_SRC/benchmarks/accelerate_opt/activator $MILABENCH_BASE/venv/torch accelerate launch --mixed_precision=fp16 --dynamo_backend=no --machine_rank=1 --num_machines=2 --multi_gpu --gradient_accumulation_steps=1 --num_cpu_threads_per_process=8 --main_process_ip=127.0.0.1 --main_process_port=22 --num_processes=16 $MILABENCH_SRC/benchmarks/accelerate_opt/main.py --max_train_steps 100 --dataset_name wikitext --dataset_config_name wikitext-103-v1 --dataset_rev b08601e --validation_split_percentage 5 --per_gpu_batch_size 1 --cpus_per_gpu 8 --model_name facebook/opt-1.3b --cache $MILABENCH_BASE/cache &
  wait
)

# ---
# opt-6_7b
# ========
(
  $MILABENCH_SRC/benchmarks/accelerate_opt/activator $MILABENCH_BASE/venv/torch accelerate launch --mixed_precision=fp16 --dynamo_backend=no --machine_rank=0 --num_machines=1 --use_deepspeed --deepspeed_multinode_launcher=standard --zero_stage=2 --gradient_accumulation_steps=1 --num_cpu_threads_per_process=8 --main_process_ip=127.0.0.1 --main_process_port=22 --num_processes=8 $MILABENCH_SRC/benchmarks/accelerate_opt/main.py --max_train_steps 100 --dataset_name wikitext --dataset_config_name wikitext-103-v1 --dataset_rev b08601e --validation_split_percentage 5 --per_gpu_batch_size 1 --cpus_per_gpu 8 --model_name facebook/opt-6.7b --cache $MILABENCH_BASE/cache &
  wait
)

# ---
# opt-6_7b-multinode
# ==================
(
  $MILABENCH_SRC/benchmarks/accelerate_opt/activator $MILABENCH_BASE/venv/torch accelerate launch --mixed_precision=fp16 --dynamo_backend=no --machine_rank=0 --num_machines=2 --use_deepspeed --deepspeed_multinode_launcher=standard --zero_stage=2 --gradient_accumulation_steps=1 --num_cpu_threads_per_process=8 --main_process_ip=127.0.0.1 --main_process_port=22 --num_processes=16 $MILABENCH_SRC/benchmarks/accelerate_opt/main.py --max_train_steps 100 --dataset_name wikitext --dataset_config_name wikitext-103-v1 --dataset_rev b08601e --validation_split_percentage 5 --per_gpu_batch_size 1 --cpus_per_gpu 8 --model_name facebook/opt-6.7b --cache $MILABENCH_BASE/cache &
  ssh -oCheckHostIP=no -oStrictHostKeyChecking=no -oPasswordAuthentication=no -oPasswordAuthentication=no -p 22 username@192.168.0.11 $MILABENCH_SRC/benchmarks/accelerate_opt/activator $MILABENCH_BASE/venv/torch accelerate launch --mixed_precision=fp16 --dynamo_backend=no --machine_rank=1 --num_machines=2 --use_deepspeed --deepspeed_multinode_launcher=standard --zero_stage=2 --gradient_accumulation_steps=1 --num_cpu_threads_per_process=8 --main_process_ip=127.0.0.1 --main_process_port=22 --num_processes=16 $MILABENCH_SRC/benchmarks/accelerate_opt/main.py --max_train_steps 100 --dataset_name wikitext --dataset_config_name wikitext-103-v1 --dataset_rev b08601e --validation_split_percentage 5 --per_gpu_batch_size 1 --cpus_per_gpu 8 --model_name facebook/opt-6.7b --cache $MILABENCH_BASE/cache &
  wait
)

# ---
# stargan
# =======
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/stargan/voirconf-stargan.D0-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/stargan/stargan/main.py --image_size 512 --c_dim 5 --batch_size 16 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/stargan/voirconf-stargan.D1-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/stargan/stargan/main.py --image_size 512 --c_dim 5 --batch_size 16 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/stargan/voirconf-stargan.D2-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/stargan/stargan/main.py --image_size 512 --c_dim 5 --batch_size 16 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/stargan/voirconf-stargan.D3-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/stargan/stargan/main.py --image_size 512 --c_dim 5 --batch_size 16 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/stargan/voirconf-stargan.D4-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/stargan/stargan/main.py --image_size 512 --c_dim 5 --batch_size 16 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/stargan/voirconf-stargan.D5-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/stargan/stargan/main.py --image_size 512 --c_dim 5 --batch_size 16 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/stargan/voirconf-stargan.D6-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/stargan/stargan/main.py --image_size 512 --c_dim 5 --batch_size 16 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/stargan/voirconf-stargan.D7-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/stargan/stargan/main.py --image_size 512 --c_dim 5 --batch_size 16 &
  wait
)

# ---
# super-slomo
# ===========
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/super-slomo/voirconf-super-slomo.D0-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/super-slomo/slomo/train.py --train_batch_size 32 &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/super-slomo/voirconf-super-slomo.D1-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/super-slomo/slomo/train.py --train_batch_size 32 &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/super-slomo/voirconf-super-slomo.D2-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/super-slomo/slomo/train.py --train_batch_size 32 &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/super-slomo/voirconf-super-slomo.D3-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/super-slomo/slomo/train.py --train_batch_size 32 &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/super-slomo/voirconf-super-slomo.D4-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/super-slomo/slomo/train.py --train_batch_size 32 &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/super-slomo/voirconf-super-slomo.D5-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/super-slomo/slomo/train.py --train_batch_size 32 &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/super-slomo/voirconf-super-slomo.D6-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/super-slomo/slomo/train.py --train_batch_size 32 &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/super-slomo/voirconf-super-slomo.D7-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/super-slomo/slomo/train.py --train_batch_size 32 &
  wait
)

# ---
# dlrm
# ====
(
  voir --config $MILABENCH_BASE/extra/dlrm/voirconf-dlrm.0-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/dlrm/dlrm/dlrm_s_pytorch.py --num-batches 1000 --data-generation random --arch-mlp-bot 512-512-64 --arch-mlp-top 1024-1024-1024-1 --arch-sparse-feature-size 64 --arch-embedding-size 1000000-1000000-1000000-1000000-1000000-1000000-1000000-1000000 --num-indices-per-lookup 100 --arch-interaction-op dot --numpy-rand-seed 727 --print-freq 999999 --mini-batch-size 16384 --test-mini-batch-size 16384 --test-num-workers 0 --use-gpu &
  wait
)

# ---
# rwkv
# ====
(
  CUDA_VISIBLE_DEVICES=0 voir --config $MILABENCH_BASE/extra/rwkv/voirconf-rwkv.D0-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/rwkv/rwkv-v4neo/train.py --data_type dummy --ctx_len 128 --epoch_steps 1000 --epoch_count 20 --epoch_begin 0 --epoch_save 0 --micro_bsz 16 --n_layer 12 --n_embd 768 --pre_ffn 0 --head_qk 0 --lr_init 6e-4 --lr_final 1e-5 --warmup_steps 0 --beta1 0.9 --beta2 0.99 --adam_eps 1e-8 --accelerator gpu --devices 1 --precision tf32 --strategy ddp_find_unused_parameters_false --grad_cp 0 --random_seed 1234 --enable_progress_bar False &
  CUDA_VISIBLE_DEVICES=1 voir --config $MILABENCH_BASE/extra/rwkv/voirconf-rwkv.D1-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/rwkv/rwkv-v4neo/train.py --data_type dummy --ctx_len 128 --epoch_steps 1000 --epoch_count 20 --epoch_begin 0 --epoch_save 0 --micro_bsz 16 --n_layer 12 --n_embd 768 --pre_ffn 0 --head_qk 0 --lr_init 6e-4 --lr_final 1e-5 --warmup_steps 0 --beta1 0.9 --beta2 0.99 --adam_eps 1e-8 --accelerator gpu --devices 1 --precision tf32 --strategy ddp_find_unused_parameters_false --grad_cp 0 --random_seed 1234 --enable_progress_bar False &
  CUDA_VISIBLE_DEVICES=2 voir --config $MILABENCH_BASE/extra/rwkv/voirconf-rwkv.D2-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/rwkv/rwkv-v4neo/train.py --data_type dummy --ctx_len 128 --epoch_steps 1000 --epoch_count 20 --epoch_begin 0 --epoch_save 0 --micro_bsz 16 --n_layer 12 --n_embd 768 --pre_ffn 0 --head_qk 0 --lr_init 6e-4 --lr_final 1e-5 --warmup_steps 0 --beta1 0.9 --beta2 0.99 --adam_eps 1e-8 --accelerator gpu --devices 1 --precision tf32 --strategy ddp_find_unused_parameters_false --grad_cp 0 --random_seed 1234 --enable_progress_bar False &
  CUDA_VISIBLE_DEVICES=3 voir --config $MILABENCH_BASE/extra/rwkv/voirconf-rwkv.D3-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/rwkv/rwkv-v4neo/train.py --data_type dummy --ctx_len 128 --epoch_steps 1000 --epoch_count 20 --epoch_begin 0 --epoch_save 0 --micro_bsz 16 --n_layer 12 --n_embd 768 --pre_ffn 0 --head_qk 0 --lr_init 6e-4 --lr_final 1e-5 --warmup_steps 0 --beta1 0.9 --beta2 0.99 --adam_eps 1e-8 --accelerator gpu --devices 1 --precision tf32 --strategy ddp_find_unused_parameters_false --grad_cp 0 --random_seed 1234 --enable_progress_bar False &
  CUDA_VISIBLE_DEVICES=4 voir --config $MILABENCH_BASE/extra/rwkv/voirconf-rwkv.D4-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/rwkv/rwkv-v4neo/train.py --data_type dummy --ctx_len 128 --epoch_steps 1000 --epoch_count 20 --epoch_begin 0 --epoch_save 0 --micro_bsz 16 --n_layer 12 --n_embd 768 --pre_ffn 0 --head_qk 0 --lr_init 6e-4 --lr_final 1e-5 --warmup_steps 0 --beta1 0.9 --beta2 0.99 --adam_eps 1e-8 --accelerator gpu --devices 1 --precision tf32 --strategy ddp_find_unused_parameters_false --grad_cp 0 --random_seed 1234 --enable_progress_bar False &
  CUDA_VISIBLE_DEVICES=5 voir --config $MILABENCH_BASE/extra/rwkv/voirconf-rwkv.D5-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/rwkv/rwkv-v4neo/train.py --data_type dummy --ctx_len 128 --epoch_steps 1000 --epoch_count 20 --epoch_begin 0 --epoch_save 0 --micro_bsz 16 --n_layer 12 --n_embd 768 --pre_ffn 0 --head_qk 0 --lr_init 6e-4 --lr_final 1e-5 --warmup_steps 0 --beta1 0.9 --beta2 0.99 --adam_eps 1e-8 --accelerator gpu --devices 1 --precision tf32 --strategy ddp_find_unused_parameters_false --grad_cp 0 --random_seed 1234 --enable_progress_bar False &
  CUDA_VISIBLE_DEVICES=6 voir --config $MILABENCH_BASE/extra/rwkv/voirconf-rwkv.D6-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/rwkv/rwkv-v4neo/train.py --data_type dummy --ctx_len 128 --epoch_steps 1000 --epoch_count 20 --epoch_begin 0 --epoch_save 0 --micro_bsz 16 --n_layer 12 --n_embd 768 --pre_ffn 0 --head_qk 0 --lr_init 6e-4 --lr_final 1e-5 --warmup_steps 0 --beta1 0.9 --beta2 0.99 --adam_eps 1e-8 --accelerator gpu --devices 1 --precision tf32 --strategy ddp_find_unused_parameters_false --grad_cp 0 --random_seed 1234 --enable_progress_bar False &
  CUDA_VISIBLE_DEVICES=7 voir --config $MILABENCH_BASE/extra/rwkv/voirconf-rwkv.D7-0efae956f1553a76c1e03985181900f5.json $MILABENCH_SRC/benchmarks/rwkv/rwkv-v4neo/train.py --data_type dummy --ctx_len 128 --epoch_steps 1000 --epoch_count 20 --epoch_begin 0 --epoch_save 0 --micro_bsz 16 --n_layer 12 --n_embd 768 --pre_ffn 0 --head_qk 0 --lr_init 6e-4 --lr_final 1e-5 --warmup_steps 0 --beta1 0.9 --beta2 0.99 --adam_eps 1e-8 --accelerator gpu --devices 1 --precision tf32 --strategy ddp_find_unused_parameters_false --grad_cp 0 --random_seed 1234 --enable_progress_bar False &
  wait
)

